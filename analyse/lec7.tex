\[
    f(X) = f(X_0) + \vec{\nabla}f(X_0)\cdot (X - X_0) + \|X - X_0\| \cdot o(X - X_0)
\] 

\begin{prop}
    $f$ est de classe  $\mathcal{C}^1$:  $f$ différentiable et 
    \begin{align*}
        : D &\longrightarrow \R^n \\
        X &\longmapsto \vec{\nabla}f(X)
    \end{align*} continue $\iff$ $f$ admet des dérviées partielles continues.
\end{prop}

\section{Extrema et points critiques}
\begin{definition}
    Extremum (local) de $f$: minimum ou maximum (local) de  $f$
\end{definition}

\begin{definition}
    $X_0$ point critique de $f$: 
     \[
         \vec{\nabla}f(X_0) = \vec{0}
    \] 
\end{definition}

\begin{theorem}
    Soit $f: D \longrightarrow \R$ différentiable, $D$ ouvert et  $X_0 \in D$ (sinon, si $D$ pas ouvert, il faut  $X_0 \in \operatorname{Int}(D)$) alors:
    \[
        X_0 \text{ extremum local } \implies X_0 \text{ point critique} 
    \] 
\end{theorem}

\begin{eg}
\begin{figure}[H]
    \centering
    \incfig{point-critique-nestpas-extremum-local}
    \caption{point-critique-nestpas-extremum-local}
    \label{fig:point-critique-nestpas-extremum-local}
\end{figure}
\end{eg}

\section{Dérivées partielles d'ordre $\ge 2$}
\begin{definition}
    Soit $D$, alors  $f: D \to \R$ est $\mathcal{C}^k$ si  $f: D \to \R$ est $\mathcal{C}^1$ et  $\partial_{x_i}f: D \to \R$ sont $C^{k-1}$
\end{definition}

\begin{definition}
    Soient $\alpha = (\alpha_1, \ldots, \alpha_n)$ \quad $\alpha_i \in \N$. On pose
    \[
        \partial_{x}^{\alpha}f = \frac{\partial^{\alpha_1}}{\partial_{x_1}^{\alpha_1}} \cdot \ldots \cdot \frac{\partial^{\alpha_n}}{\partial_{x_n}^{\alpha_n}}
    \] 
    \[
        \frac{\partial}{\partial_{x_1}}\frac{\partial}{\partial_{x_2}}\frac{\partial}{\partial_{x_1}} f \overset{?}{=}  \frac{\partial^2}{\partial_{x_1}^2}\frac{\partial}{\partial_{x_2}}f
    \] 
\end{definition}

\begin{theorem}
    Lemme de Schwarz
    \par
    Si $f \in \mathcal{C}^2(D)$ alors 
    \[
        \displaystyle \frac{\partial^2 f}{\partial_{x_i}\partial_{x_j}}(X) = \frac{\partial^2 f}{\partial_{x_j}\partial_{x_i}}(X) \qquad \forall X \in D, \forall i, j
    \] 
\end{theorem}
\begin{eg}
   \[
   f(x_1, x_2) = \begin{cases}
       x_1x_2 \frac{x_1^2 - x_2^2}{x_1^2 + x_2^2} \text{ si } (x_1, x_2) \neq (0, 0)\\
       0 \text{ si } (x_1, x_2) = 0
   \end{cases}
   \]  
   \[
   r^2 \sin(\theta)\cos(\theta)\cos(2\theta) = \frac{1}{4}r^2\sin(4\theta)
   \] 
   On calcule $\displaystyle \frac{\partial^2f}{\partial_{x_1}\partial_{x_2}}(0, 0)$?
       C'est $\displaystyle \frac{\partial}{\partial x_1}g(x_1)$ en $x_1 = 0$ pour $\displaystyle g(x_1) = \frac{\partial f}{\partial x_2}(x_1, x_2)|_{x_2 = 0}$. Calcul de $g(x_1)$:
    \begin{enumerate}
        \item si $x_1 \neq 0$ $\frac{\partial f}{\partial x_2}(x_1, x_2) = x_1 \frac{x_1 ^ 2 - x_2^2}{x_1^2 + x_2^2}$, donc si $x_1 \neq 0$ $\frac{\partial f}{\partial x_2}(x_1, 0) = x_1$ 
        \item si $x_1 = 0$ $f(0, x_2) = 0$
    \end{enumerate}
    Conclusion:
    \[
    \frac{\partial f}{\partial x_2}(x_1, 0) = x_1 \quad \forall x_1
    \] 
    donc: 
    \[
    \frac{\partial}{\partial x_1}\frac{\partial}{\partial x_2}f(0, 0) = 1
    \] 
    $\displaystyle \frac{\partial}{\partial x_2}\frac{\partial}{\partial x_1}f(0, 0) = ?$. On voit que, $f(x_2, x_1) = -f(x_1, x_2)$ donc 
    \[
    \frac{\partial}{\partial x_2}\frac{\partial}{\partial x_1}f(0, 0) = - \frac{\partial}{\partial x_1}\frac{\partial}{\partial x_2}f(0, 0) = -1
    \] 
\end{eg}

\begin{definition}
    Soit $f \in \mathcal{C}^2(D)$. Matrice hessienne: matrice  $n \times n$
    \[
    H_f(X_0) = \begin{bmatrix} \frac{\partial^2}{\partial x_i \partial x_j}(X_0) \end{bmatrix} 1\le i,j \le n
    \] 
    \[
        \vec{\nabla}f(X_0) = \begin{pmatrix} \frac{\partial f}{\partial x_1}(X_0) \\ \vdots \\ \frac{\partial f}{\partial x_n}(X_0) \end{pmatrix} 
    \] 
\end{definition}

\begin{theorem} De Taylor à l'ordre 2 \par
    Soit $f \in \mathcal{C}^2(D)$,  $X_0 \in D$. Alors  
    \begin{align*}
        f(X_0 + \vec{X}) = f(X_0) + \vec{\nabla }f(X_0) \cdot \vec{X} + \frac{1}{2}\vec{X} \cdot H_f(X_0)\vec{X}
    \end{align*}
    exemple en $\R^1$
    \[
    f(x_0 + x) = f(x_0) + f'(x_0)x + \frac{1}{2}f''(x_0)x^2 + \ldots
    \] 
\end{theorem}
\begin{intuition}
   Alors, matrice hessienne sert à calculer dérivée d'ordre 2. 
\end{intuition}

\[
    \vec{X} \cdot A\vec{X} = \sum_{1\le i,j \le n}^{} x_ia_{i,j}x_j
\] 
Si $\vec{X} = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix}$ $A = \begin{bmatrix} a_{i,j} \end{bmatrix}$ on a: $X \mapsto X \cdot AX$ à étudier. Si $A = A^T, A \in \mathcal{M}_n(\R)$
\begin{center}
   "$A$ admet une base orthonormée de vecteurs propres" 
\end{center}
Il existe une base $\vec{u_1}, \ldots, \vec{u_n}$ de $\R^n$ avec $\vec{u_i} \cdot \vec{u_j} = \delta_{i, j}$ ($1$ si  $i = j$ et  $0$ sinon) et des réels $\lambda_1, \ldots, \lambda_n$($\lambda_i = \lambda_j$ possible) tels que
\[
    A\vec{u_i} = \lambda_i\vec{u_i}
\] 
\[
    \vec{X} = \sum_{j=1}^{n} y_j\vec{u_j}
\] 
\[
    \vec{X} \cdot \vec{u_i} = \sum_{j=1}^{n} y_j\vec{u_j}\vec{u_i} = y_i
\] 
\begin{align*}
    \|\vec{X}\|^2 = \vec{X} \cdot \vec{X} &= \left( \sum_{j=1}^{n} y_j\vec{u_j} \right) \cdot \left( \sum_{i=1}^{n} y_i\vec{u_i} \right) \\
                                          &= \sum_{j=1}^{n} \sum_{i=1}^{n} y_jy_i\vec{u_j}\cdot \vec{u_i}\\ 
                                          &= \sum_{j=1}^{n} y_j^2
\end{align*}

\begin{align*}
    A\vec{X} = A \sum_{j=1}^{n} y_j\vec{u_j} = \sum_{j=1}^{n} y_jA\vec{u_j} = \sum_{j=1}^{n} \lambda_jy_j\vec{u_j}
\end{align*}
\[
    \vec{X} \cdot A\vec{X} = \sum_{i=1}^{n} \lambda_iy_i^2
\] 
\begin{enumerate}
    \item si $\lambda_i > 0$ ($1 \le i \le n$)
        \[
        C = \min \lambda_i > 0
        \] 
        \[
        X \cdot AX \ge C \sum_{i=1}^{n} y_i^2 = C \|X\|^2
        \] 
    \item si $\lambda_i < 0$ ($1 \le i \le n$)
        \[
        -C = \max \lambda_i < 0
        \] 
        \[
        X \cdot AX \le -C\|X\|^2
        \] 
\end{enumerate}
\begin{eg}
   $n = 2$ 
   \[
   f(y_1, y_2) = -y_1^2 + 3y_2^2
   \] 
   \[
   \lambda_1 = -1 \qquad \lambda_2 = 3
   \] 
   \[
   f(y_1, 0) < f(0, 0) < f(0, y_2)
   \] 
\end{eg}

\begin{theorem}\label{thm:nature-des-points-critiques}
    (Nature des points critiques) \par
    Soient $f \in \mathcal{C}^2(D)$,  $X_0 \in D$, $D$ ouvert et  $\vec{\nabla }f(X_0) = \vec{0}$
    \begin{enumerate}
        \item si toutes les valeurs propres de $H_f(X_0)$ sont $> 0$ (resp $< 0$) $X_0$ est minimum (resp. maximum) local.
        \item si toutes les valeurs propres de $H_f(X_0)$ sont \underline{non nulles} mais pas de même signe, $X_0$ n'est pas un extremum local: $X_0$ est un point selle (un col).
        \item si 0 valeurs propres de $H_f(X_0)$, pas de conclusion, ($X_0$ point critique dégénéré)
    \end{enumerate}
\end{theorem}

\begin{eg}
   \[
   f(x, y) = \frac{1}{2}(x^2 - y^2)
   \]  
   \[
       H_f(0, 0) = \begin{pmatrix} 1 & 0\\ 0 & -1 \end{pmatrix} 
   \] 
   \[
       I_f = \{(x, y, z): z = \frac{1}{2}(x^2 - y^2)\}
   \] 
\begin{figure}[H]
    \centering
    \incfig{exemple-point-selle}
    \caption{exemple-point-selle}
    \label{fig:exemple-point-selle}
\end{figure}
\end{eg}
\[
    \vec{\nabla }f(X_0) = \vec{0}!
\] 
\begin{preuve} du théorème ~\ref{thm:nature-des-points-critiques}
   \[
       f(X_0 + X) - f(X_0) = \frac{1}{2}X\cdot H_f(X_0)X + \|X\|^2\epsilon(X)
   \]  
   .
   \begin{enumerate}
       \item si $\lambda_i > 0$  $\frac{1}{2}X \cdot H_f(X_0)X \ge C\|X\|^2$ $C > 0$
            \[
           f(X_0 + X) - f(X_0) \ge \|X\|^2(C + \epsilon(X)) \ge \frac{C}{2}\|X\|^2 \text{ si } \|X\| \text{ assez petit }
           \] 
           \[
           \implies X_0 \text{ minimum local}
           \] 
        \item si $\lambda_1 < 0$ et  $\lambda_2 > 0$
             \[
                 H_f(X_0)\vec{u_i} = \lambda_i\vec{u_i}
            \] 
            \[
                f(X_0 + t\vec{u_i}) = f(X_0) + \frac{1}{2} \lambda_it^2 + t^2\epsilon(t)
            \] 
            \[
                \epsilon(t\vec{u_i}) = \epsilon(t)
            \] 
            \[
                f(X_0 + t\vec{u_i}) - f(X_0) = t^2 (\frac{1}{2}\lambda_i + \epsilon(t))
            \] 
            si $i = 1$  $< 0$  $|t|$ petit,  $i = 2$  $> 0$  $|t|$ petit, alors  $X_0$ n'est pas un extremum local
   \end{enumerate}
\end{preuve}

$n = 2$
 \[
A = \begin{pmatrix} 
    a_{1,1} & a_{1, 2}\\
    a_{2, 1} & a_{2, 2}
\end{pmatrix} 
\] 
$(a_{1,2} = a_{2, 1})$
\par
Valeurs propres: racines du pol. Caractéristique:  
\[
    P(\lambda) = \det(A - \lambda I) = \begin{vmatrix} a_{1,1} - \lambda & a_{1, 2} \\ a_{2, 1} & a_{2,2} - \lambda \end{vmatrix} = (\lambda - a_{1,1})(\lambda - a_{2,2}) -  a_{1,2}a_{2,1}
\] 
\[
    \lambda^2 - (a_{1,1} + a_{2,2})\lambda + a_{1,1}a_{2,2} - a_{2,1}a_{1,2}
\] 
\[
    a_{1,1} + a_{2,2} = Tr(A)
\] 
\[
    a_{1,1}a_{2,2} - a_{2,1}a_{1,2} = \det(A)
\] 
\[
    x^2 - Sx + P = x^2 - (\lambda_1 + \lambda_2)x + \lambda_1\lambda_2
\] 
\begin{align*}
    &\det(A) = \text{ produit des valeurs propres}\\
    &Tr(A) = \text{ somme des valeurs propres}
\end{align*}
\[
A = H_f(X_0)
\] 
\begin{enumerate}
    \item si $\det(A) < 0$,  $X_0$ point col
    \item si $\det(A) > 0$
         \begin{enumerate}
            \item $Tr(A) > 0$, $X_0$ minimum
            \item  $Tr(A) < 0$, $X_0$ maximum
        \end{enumerate}
    \item $\det(A) = 0$,  $X_0$ point critique dégénéré
\end{enumerate}

\chapter{Espaces vectoriels normés}
Soient:
\begin{itemize}
    \item espace vectoriel $E$,  $F$, etc
    \item vecteurs:  $x, y, e$, etc.
    \item vecteur nul: noté  $0_E$ ou simplement  $0$
    \item scalaires:  $\lambda, \mu \in \mathbb{K}$
    \item  $\mathbb{K} = \R \text{ ou } \mathbb{C}$
    \item $A \in \mathcal{L}(E, F)$ action sur $x$, notée  $Ax$ (plutôt que $A(x)$)
    \item dimension: $E$ de dimension finie si  $E$ admet une base avec un nombre fini d'éléments, sinon  $E$ est dit de dimension infinie  $\iff$ $\forall N \in \N$, il existe une famille libre de $N$ vecteurs. La dimension dépend de  $\mathbb{K}$!
         \begin{itemize}
             \item sur $\mathbb{C}$  $\dim \mathbb{C} = 1$ base formée du vecteur  $1 \in \mathbb{C}$
             \item sur  $\R$ $\dim \mathbb{C} = 2$ base formée de $1, i$
        \end{itemize}
        \begin{align*}
            &z = z \cdot 1 \quad z \in \mathbb{C}\\
            &z = x \cdot 1 + y \cdot i \quad x, y \in \R
        \end{align*}
        \[
            \mathbb{C} \sim \R^2 \text{ comme } \R \text{ espace vectoriel}
        \] 
\end{itemize}
